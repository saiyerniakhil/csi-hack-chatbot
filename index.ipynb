{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "import langchain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain import OpenAI, VectorDBQA\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, HTML, display  \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"env2.env\")\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "    \n",
    "#os.makedirs(\"data/books/\",exist_ok=True)\n",
    "    \n",
    "\n",
    "BLOB_CONTAINER_NAME = \"acccsuite\"\n",
    "BASE_CONTAINER_URL = \"https://synpasedlstore.blob.core.windows.net/\" + BLOB_CONTAINER_NAME + \"/\"\n",
    "#LOCAL_FOLDER = \"./data/books/\"\n",
    "\n",
    "MODEL = \"gpt-35-turbo-16k\" # options: gpt-35-turbo, gpt-35-turbo-16k, gpt-4, gpt-4-32k\n",
    "\n",
    "#os.makedirs(LOCAL_FOLDER,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import dotenv_values, load_dotenv\n",
    "# specify the name of the .env file name \n",
    "env_name = \".env2.env\" # change to use your own .env file\n",
    "config = dotenv_values(env_name)\n",
    "load_dotenv(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set env variables \n",
    "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "# print(dict(config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pdf(file, form_recognizer=False, formrecognizer_endpoint=None, formrecognizerkey=None, model=\"prebuilt-document\", from_url=False, verbose=False):\n",
    "    \"\"\"Parses PDFs using PyPDF or Azure Document Intelligence SDK (former Azure Form Recognizer)\"\"\"\n",
    "    offset = 0\n",
    "    page_map = []\n",
    "    if not form_recognizer:\n",
    "        if verbose: print(f\"Extracting text using PyPDF\")\n",
    "        reader = PdfReader(file)\n",
    "        pages = reader.pages\n",
    "        for page_num, p in enumerate(pages):\n",
    "            page_text = p.extract_text()\n",
    "            page_map.append((page_num, offset, page_text))\n",
    "            offset += len(page_text)\n",
    "    else:\n",
    "        if verbose: print(f\"Extracting text using Azure Document Intelligence\")\n",
    "        credential = AzureKeyCredential(os.environ[\"FORM_RECOGNIZER_KEY\"])\n",
    "        form_recognizer_client = DocumentAnalysisClient(endpoint=os.environ[\"FORM_RECOGNIZER_ENDPOINT\"], credential=credential)\n",
    "        \n",
    "        if not from_url:\n",
    "            with open(file, \"rb\") as filename:\n",
    "                poller = form_recognizer_client.begin_analyze_document(model, document = filename)\n",
    "        else:\n",
    "            poller = form_recognizer_client.begin_analyze_document_from_url(model, document_url = file)\n",
    "            \n",
    "        form_recognizer_results = poller.result()\n",
    "\n",
    "        for page_num, page in enumerate(form_recognizer_results.pages):\n",
    "            tables_on_page = [table for table in form_recognizer_results.tables if table.bounding_regions[0].page_number == page_num + 1]\n",
    "\n",
    "            # mark all positions of the table spans in the page\n",
    "            page_offset = page.spans[0].offset\n",
    "            page_length = page.spans[0].length\n",
    "            table_chars = [-1]*page_length\n",
    "            for table_id, table in enumerate(tables_on_page):\n",
    "                for span in table.spans:\n",
    "                    # replace all table spans with \"table_id\" in table_chars array\n",
    "                    for i in range(span.length):\n",
    "                        idx = span.offset - page_offset + i\n",
    "                        if idx >=0 and idx < page_length:\n",
    "                            table_chars[idx] = table_id\n",
    "\n",
    "            # build page text by replacing charcters in table spans with table html\n",
    "            page_text = \"\"\n",
    "            added_tables = set()\n",
    "            for idx, table_id in enumerate(table_chars):\n",
    "                if table_id == -1:\n",
    "                    page_text += form_recognizer_results.content[page_offset + idx]\n",
    "                elif not table_id in added_tables:\n",
    "                    page_text += table_to_html(tables_on_page[table_id])\n",
    "                    added_tables.add(table_id)\n",
    "\n",
    "            page_text += \" \"\n",
    "            page_map.append((page_num, offset, page_text))\n",
    "            offset += len(page_text)\n",
    "\n",
    "    return page_map\n",
    "\n",
    "#function to create from pdf to html\n",
    "def table_to_html(table):\n",
    "    table_html = \"<table>\"\n",
    "    rows = [sorted([cell for cell in table.cells if cell.row_index == i], key=lambda cell: cell.column_index) for i in range(table.row_count)]\n",
    "    for row_cells in rows:\n",
    "        table_html += \"<tr>\"\n",
    "        for cell in row_cells:\n",
    "            tag = \"th\" if (cell.kind == \"columnHeader\" or cell.kind == \"rowHeader\") else \"td\"\n",
    "            cell_spans = \"\"\n",
    "            if cell.column_span > 1: cell_spans += f\" colSpan={cell.column_span}\"\n",
    "            if cell.row_span > 1: cell_spans += f\" rowSpan={cell.row_span}\"\n",
    "            table_html += f\"<{tag}{cell_spans}>{html.escape(cell.content)}</{tag}>\"\n",
    "        table_html +=\"</tr>\"\n",
    "    table_html += \"</table>\"\n",
    "    return table_html\n",
    "\n",
    "#text to base64 encoding helper function\n",
    "def text_to_base64(text):\n",
    "    # Convert text to bytes using UTF-8 encoding\n",
    "    bytes_data = text.encode('utf-8')\n",
    "\n",
    "    # Perform Base64 encoding\n",
    "    base64_encoded = base64.b64encode(bytes_data)\n",
    "\n",
    "    # Convert the result back to a UTF-8 string representation\n",
    "    base64_text = base64_encoded.decode('utf-8')\n",
    "\n",
    "    return base64_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_index_name = \"hackchat\"\n",
    "\n",
    "### Create Azure Search Vector-based Index\n",
    "# Setup the Payloads header\n",
    "headers = {'Content-Type': 'application/json','api-key': os.environ['AZURE_SEARCH_KEY']}\n",
    "params = {'api-version': os.environ['AZURE_SEARCH_API_VERSION']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nindex_payload = {\\n    \"@odata.context\": \"https://hackcsi.search.windows.net/$metadata#indexes/$entity\",\\n    \"@odata.etag\": \"\"0x8DBF02FAD913FA2\"\",\\n    \"name\": \"hackchat\",\\n    \"fields\": [\\n      {\\n        \"name\": \"content\",\\n        \"type\": \"Edm.String\",\\n        \"searchable\": \"true\",\\n        \"filterable\": \"false\",\\n        \"retrievable\": \"true\",\\n        \"sortable\": \"false\",\\n        \"facetable\": \"false\",\\n        \"key\": \"false\",\\n        \"synonymMaps\": []\\n      },\\n      {\\n        \"name\": \"filepath\",\\n        \"type\": \"Edm.String\",\\n        \"searchable\": \"false\",\\n        \"filterable\": \"false\",\\n        \"retrievable\": \"true\",\\n        \"sortable\": \"false\",\\n        \"facetable\": \"false\",\\n        \"key\": \"false\",\\n        \"synonymMaps\": []\\n      },\\n      {\\n        \"name\": \"title\",\\n        \"type\": \"Edm.String\",\\n        \"searchable\": \"true\",\\n        \"filterable\": \"false\",\\n        \"retrievable\": \"true\",\\n        \"sortable\": \"false\",\\n        \"facetable\": \"false\",\\n        \"key\": \"false\",\\n        \"synonymMaps\": []\\n      },\\n      {\\n        \"name\": \"url\",\\n        \"type\": \"Edm.String\",\\n        \"searchable\": \"false\",\\n        \"filterable\": \"false\",\\n        \"retrievable\": \"true\",\\n        \"sortable\": \"false\",\\n        \"facetable\": \"false\",\\n        \"key\": \"false\",\\n        \"synonymMaps\": []\\n      },\\n      {\\n        \"name\": \"id\",\\n        \"type\": \"Edm.String\",\\n        \"searchable\": \"false\",\\n        \"filterable\": \"true\",\\n        \"retrievable\": \"true\",\\n        \"sortable\": \"true\",\\n        \"facetable\": \"false\",\\n        \"key\": \"true\",\\n        \"synonymMaps\": []\\n      },\\n      {\\n        \"name\": \"chunk_id\",\\n        \"type\": \"Edm.String\",\\n        \"searchable\": \"false\",\\n        \"filterable\": \"false\",\\n        \"retrievable\": \"true\",\\n        \"sortable\": \"false\",\\n        \"facetable\": \"false\",\\n        \"key\": \"false\",\\n        \"synonymMaps\": []\\n      },\\n      {\\n        \"name\": \"last_updated\",\\n        \"type\": \"Edm.String\",\\n        \"searchable\": \"false\",\\n        \"filterable\": \"false\",\\n        \"retrievable\": \"true\",\\n        \"sortable\": \"false\",\\n        \"facetable\": \"false\",\\n        \"key\": \"false\",\\n        \"synonymMaps\": []\\n      }\\n    ],\\n    \"scoringProfiles\": [],\\n    \"corsOptions\": {\\n      \"allowedOrigins\": [\\n        \"*\"\\n      ],\\n      \"maxAgeInSeconds\": 300\\n    },\\n    \"semantic\": {\\n      \"configurations\": [\\n        {\\n          \"name\": \"default\",\\n          \"prioritizedFields\": {\\n            \"titleField\": {\\n              \"fieldName\": \"title\"\\n            },\\n            \"prioritizedContentFields\": [\\n              {\\n                \"fieldName\": \"content\"\\n              }\\n            ],\\n            \"prioritizedKeywordsFields\": []\\n          }\\n        }\\n      ]\\n    },\\n  }\\nr = requests.put(os.environ[\\'AZURE_SEARCH_ENDPOINT\\'] + \"/indexes/\" + profile_index_name,\\n                 data=json.dumps(index_payload), headers=headers, params=params)\\nprint(r.status_code)\\nprint(r.ok)\\nprint(r.json())\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#not needed mostly TODO: we'll see this later\n",
    "\"\"\"\n",
    "index_payload = {\n",
    "    \"@odata.context\": \"https://hackcsi.search.windows.net/$metadata#indexes/$entity\",\n",
    "    \"@odata.etag\": \"\\\"0x8DBF02FAD913FA2\\\"\",\n",
    "    \"name\": \"hackchat\",\n",
    "    \"fields\": [\n",
    "      {\n",
    "        \"name\": \"content\",\n",
    "        \"type\": \"Edm.String\",\n",
    "        \"searchable\": \"true\",\n",
    "        \"filterable\": \"false\",\n",
    "        \"retrievable\": \"true\",\n",
    "        \"sortable\": \"false\",\n",
    "        \"facetable\": \"false\",\n",
    "        \"key\": \"false\",\n",
    "        \"synonymMaps\": []\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"filepath\",\n",
    "        \"type\": \"Edm.String\",\n",
    "        \"searchable\": \"false\",\n",
    "        \"filterable\": \"false\",\n",
    "        \"retrievable\": \"true\",\n",
    "        \"sortable\": \"false\",\n",
    "        \"facetable\": \"false\",\n",
    "        \"key\": \"false\",\n",
    "        \"synonymMaps\": []\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"title\",\n",
    "        \"type\": \"Edm.String\",\n",
    "        \"searchable\": \"true\",\n",
    "        \"filterable\": \"false\",\n",
    "        \"retrievable\": \"true\",\n",
    "        \"sortable\": \"false\",\n",
    "        \"facetable\": \"false\",\n",
    "        \"key\": \"false\",\n",
    "        \"synonymMaps\": []\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"url\",\n",
    "        \"type\": \"Edm.String\",\n",
    "        \"searchable\": \"false\",\n",
    "        \"filterable\": \"false\",\n",
    "        \"retrievable\": \"true\",\n",
    "        \"sortable\": \"false\",\n",
    "        \"facetable\": \"false\",\n",
    "        \"key\": \"false\",\n",
    "        \"synonymMaps\": []\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"id\",\n",
    "        \"type\": \"Edm.String\",\n",
    "        \"searchable\": \"false\",\n",
    "        \"filterable\": \"true\",\n",
    "        \"retrievable\": \"true\",\n",
    "        \"sortable\": \"true\",\n",
    "        \"facetable\": \"false\",\n",
    "        \"key\": \"true\",\n",
    "        \"synonymMaps\": []\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"chunk_id\",\n",
    "        \"type\": \"Edm.String\",\n",
    "        \"searchable\": \"false\",\n",
    "        \"filterable\": \"false\",\n",
    "        \"retrievable\": \"true\",\n",
    "        \"sortable\": \"false\",\n",
    "        \"facetable\": \"false\",\n",
    "        \"key\": \"false\",\n",
    "        \"synonymMaps\": []\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"last_updated\",\n",
    "        \"type\": \"Edm.String\",\n",
    "        \"searchable\": \"false\",\n",
    "        \"filterable\": \"false\",\n",
    "        \"retrievable\": \"true\",\n",
    "        \"sortable\": \"false\",\n",
    "        \"facetable\": \"false\",\n",
    "        \"key\": \"false\",\n",
    "        \"synonymMaps\": []\n",
    "      }\n",
    "    ],\n",
    "    \"scoringProfiles\": [],\n",
    "    \"corsOptions\": {\n",
    "      \"allowedOrigins\": [\n",
    "        \"*\"\n",
    "      ],\n",
    "      \"maxAgeInSeconds\": 300\n",
    "    },\n",
    "    \"semantic\": {\n",
    "      \"configurations\": [\n",
    "        {\n",
    "          \"name\": \"default\",\n",
    "          \"prioritizedFields\": {\n",
    "            \"titleField\": {\n",
    "              \"fieldName\": \"title\"\n",
    "            },\n",
    "            \"prioritizedContentFields\": [\n",
    "              {\n",
    "                \"fieldName\": \"content\"\n",
    "              }\n",
    "            ],\n",
    "            \"prioritizedKeywordsFields\": []\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "  }\n",
    "r = requests.put(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + profile_index_name,\n",
    "                 data=json.dumps(index_payload), headers=headers, params=params)\n",
    "print(r.status_code)\n",
    "print(r.ok)\n",
    "print(r.json())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-30\n",
      "==========================\n",
      "manuals {}\n",
      "yes manuals\n",
      "[{'name': 'User Manuals/CSI Phase 1 rev 3 capital removed.pdf', 'container': 'manuals', 'snapshot': None, 'version_id': None, 'is_current_version': None, 'blob_type': <BlobType.BLOCKBLOB: 'BlockBlob'>, 'metadata': {}, 'encrypted_metadata': None, 'last_modified': datetime.datetime(2023, 11, 10, 22, 11, 8, tzinfo=datetime.timezone.utc), 'etag': '0x8DBE239F0B376DA', 'size': 1154207, 'content_range': None, 'append_blob_committed_block_count': None, 'is_append_blob_sealed': None, 'page_blob_sequence_number': None, 'server_encrypted': True, 'copy': {'id': None, 'source': None, 'status': None, 'progress': None, 'completion_time': None, 'status_description': None, 'incremental_copy': None, 'destination_snapshot': None}, 'content_settings': {'content_type': 'application/pdf', 'content_encoding': None, 'content_language': None, 'content_md5': bytearray(b'Q|L>e\\x17\\xf4\\x9d\\x9f\\xe5\\x03\\r\\x0cW\\x98\\x84'), 'content_disposition': None, 'cache_control': None}, 'lease': {'status': 'unlocked', 'state': 'available', 'duration': None}, 'blob_tier': 'Hot', 'rehydrate_priority': None, 'blob_tier_change_time': None, 'blob_tier_inferred': True, 'deleted': None, 'deleted_time': None, 'remaining_retention_days': None, 'creation_time': datetime.datetime(2023, 11, 10, 22, 11, 8, tzinfo=datetime.timezone.utc), 'archive_status': None, 'encryption_key_sha256': None, 'encryption_scope': None, 'request_server_encrypted': None, 'object_replication_source_properties': [], 'object_replication_destination_policy': None, 'last_accessed_on': None, 'tag_count': None, 'tags': None, 'immutability_policy': {'expiry_time': None, 'policy_mode': None}, 'has_legal_hold': None, 'has_versions_only': None}, {'name': 'User Manuals/Operation and Maintenance Manual.pdf', 'container': 'manuals', 'snapshot': None, 'version_id': None, 'is_current_version': None, 'blob_type': <BlobType.BLOCKBLOB: 'BlockBlob'>, 'metadata': {}, 'encrypted_metadata': None, 'last_modified': datetime.datetime(2023, 11, 10, 22, 11, 10, tzinfo=datetime.timezone.utc), 'etag': '0x8DBE239F227F94F', 'size': 2986787, 'content_range': None, 'append_blob_committed_block_count': None, 'is_append_blob_sealed': None, 'page_blob_sequence_number': None, 'server_encrypted': True, 'copy': {'id': None, 'source': None, 'status': None, 'progress': None, 'completion_time': None, 'status_description': None, 'incremental_copy': None, 'destination_snapshot': None}, 'content_settings': {'content_type': 'application/pdf', 'content_encoding': None, 'content_language': None, 'content_md5': bytearray(b'd\\xac\\xfa\\xf8\\x9c\\xc9\\xa5\\xec\\xdc\\n(T\\xc7\\xc7R$'), 'content_disposition': None, 'cache_control': None}, 'lease': {'status': 'unlocked', 'state': 'available', 'duration': None}, 'blob_tier': 'Hot', 'rehydrate_priority': None, 'blob_tier_change_time': None, 'blob_tier_inferred': True, 'deleted': None, 'deleted_time': None, 'remaining_retention_days': None, 'creation_time': datetime.datetime(2023, 11, 10, 22, 11, 10, tzinfo=datetime.timezone.utc), 'archive_status': None, 'encryption_key_sha256': None, 'encryption_scope': None, 'request_server_encrypted': None, 'object_replication_source_properties': [], 'object_replication_destination_policy': None, 'last_accessed_on': None, 'tag_count': None, 'tags': None, 'immutability_policy': {'expiry_time': None, 'policy_mode': None}, 'has_legal_hold': None, 'has_versions_only': None}, {'name': 'User Manuals/Operations Manual.pdf', 'container': 'manuals', 'snapshot': None, 'version_id': None, 'is_current_version': None, 'blob_type': <BlobType.BLOCKBLOB: 'BlockBlob'>, 'metadata': {}, 'encrypted_metadata': None, 'last_modified': datetime.datetime(2023, 11, 10, 22, 11, 14, tzinfo=datetime.timezone.utc), 'etag': '0x8DBE239F4756D2F', 'size': 6844458, 'content_range': None, 'append_blob_committed_block_count': None, 'is_append_blob_sealed': None, 'page_blob_sequence_number': None, 'server_encrypted': True, 'copy': {'id': None, 'source': None, 'status': None, 'progress': None, 'completion_time': None, 'status_description': None, 'incremental_copy': None, 'destination_snapshot': None}, 'content_settings': {'content_type': 'application/pdf', 'content_encoding': None, 'content_language': None, 'content_md5': bytearray(b\"\\xab\\xb9F\\'\\xd2\\x1b+\\x08\\xce\\x0e\\x08}\\x93\\\\Ti\"), 'content_disposition': None, 'cache_control': None}, 'lease': {'status': 'unlocked', 'state': 'available', 'duration': None}, 'blob_tier': 'Hot', 'rehydrate_priority': None, 'blob_tier_change_time': None, 'blob_tier_inferred': True, 'deleted': None, 'deleted_time': None, 'remaining_retention_days': None, 'creation_time': datetime.datetime(2023, 11, 10, 22, 11, 14, tzinfo=datetime.timezone.utc), 'archive_status': None, 'encryption_key_sha256': None, 'encryption_scope': None, 'request_server_encrypted': None, 'object_replication_source_properties': [], 'object_replication_destination_policy': None, 'last_accessed_on': None, 'tag_count': None, 'tags': None, 'immutability_policy': {'expiry_time': None, 'policy_mode': None}, 'has_legal_hold': None, 'has_versions_only': None}]\n"
     ]
    }
   ],
   "source": [
    "from typing import Container\n",
    "#from azure.cosmosdb.table.tableservice import TableService,ListGenerator\n",
    "from azure.storage.blob import BlobClient, BlobServiceClient, ContainerClient\n",
    "from azure.storage.blob import ResourceTypes, AccountSasPermissions\n",
    "from azure.storage.blob import generate_account_sas    \n",
    "from datetime import *\n",
    "import shutil\n",
    "\n",
    "today = str(datetime.now().date())\n",
    "print(today)\n",
    "\n",
    "#================================ SOURCE ===============================\n",
    "# Source Client\n",
    "# connection_string = 'xxxxxxxxxxxxxxxxxxxxxx' # The connection string for the source container\n",
    "# account_key = 'xxxxxxxxxxxxxxxxx' # The account key for the source container\n",
    "source_container_name = 'manuals' # Name of container which has blob to be copied\n",
    "connection_string = config[\"DOCUMENT_AZURE_STORAGE_CONNECTION_STRING\"]\n",
    "account_key= config[\"DOCUMENT_AZURE_STORAGE_CONNECTION_KEY\"]\n",
    "\n",
    "# Create client\n",
    "client = BlobServiceClient.from_connection_string(connection_string) \n",
    "\n",
    "client = BlobServiceClient.from_connection_string(connection_string)\n",
    "all_containers = client.list_containers(include_metadata=True)\n",
    "# print(list(all_containers))\n",
    "\n",
    "for container in all_containers:\n",
    "    print(\"==========================\")\n",
    "    print(container['name'], container['metadata'])\n",
    "    if container['name'] == 'manuals':\n",
    "        print(\"yes\", container.name)\n",
    "        \n",
    "        container_client = client.get_container_client(container.name)\n",
    "        blobs_list = container_client.list_blobs(name_starts_with=\"User Manuals/\")\n",
    "\n",
    "        # print(list(blobs_list))\n",
    "        \n",
    "        for blob in blobs_list:\n",
    "            print(blob.name)\n",
    "            target_blob_name = blob.name\n",
    "            print(target_blob_name)\n",
    "            blob_client = client.get_blob_client(container=container['name'], blob=blob.name)\n",
    "            with open(file=os.path.join(r'', blob.name), mode=\"wb+\") as sample_blob:\n",
    "                download_stream = blob_client.download_blob(max_concurrency=2)\n",
    "                destfile = os.path.join(r'data/profiles', blob.name)\n",
    "                sample_blob.write(download_stream.readall())\n",
    "                shutil.move(blob.name, destfile)\n",
    "                with open(destfile, \"w\") as file:\n",
    "                    file.write(download_stream.readall())\n",
    "                    file.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
